
<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Publications</title>
  <meta name="description" content="Yeon-Ji's personal website">

  <!-- Open Graph -->


  <!-- Bootstrap & MDB -->
  <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

  <!-- Fonts & Icons -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
  <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

  <!-- Code Syntax Highlighting -->
  <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

  <!-- Styles -->
  <link rel="shortcut icon" href="/assets/img/favicon.ico">
  <link rel="stylesheet" href="main.css">

  <link rel="canonical" href="publication">

  <!-- Theming-->



  <!-- MathJax -->
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


</head>

<body class="fixed-top-nav sticky-bottom-footer">

  <!-- Header -->

  <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
      <div class="container">

        <a class="navbar-brand title font-weight-lighter" href="./index.html">
         <span class="font-weight-bold">Yeon-Ji Song</span>
       </a>

       <!-- Navbar Toogle -->
       <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <li class="nav-item ">
            <a class="nav-link" href="index.html">About</a>
          </li>        
          <li class="nav-item active">
            <a class="nav-link" href="publications.html">
              Publications
              <span class="sr-only">(current)</span>
            </a>
          </li>

          <li class="nav-item ">
            <a class="nav-link" target="_blank" href="cv.pdf">CV</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

</header>


<!-- Content -->

<div class="container mt-5">
  <div class="post">

    <header class="post-header">
      <h1 class="post-title">Publications</h1>
      <p class="post-description">
        (&#x2A) denotes corresponding author. <br>
        (&#x23) denotes equal contribution.
      </p>
    </header>

    <article>
      <!-- An up-to-date list is available on <a href="https://scholar.google.com/citations?user=VdlgOXoAAAAJ&hl=en" target="\_blank">Google Scholar</a> -->
      <div class="publications">

        <h2 class="year">2024</h2>
        <ol class="bibliography">

          <li>
            <div class="row">
              <div class="col-sm-2 abbr">
                <abbr class="badge">arXiv</abbr>
                <!-- <span class="award badge">Oral</span> -->
              </div>
              <div id="" class="col-sm-8">
                <div class="title">Unsupervised Dynamics Prediction with Object-Centric Kinematics</div>
                <div class="author">
                  <em>Yeon-Ji Song</em>, Suhyung Choi, Jaein Kim, Jin-Hwa Kim*, Byoung-Tak Zhang*
                </div>
                <div class="periodical">
                  <em>Under review</em>
                  <!-- ,2024 -->
                </div>   

                <div class="links">
                  <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                  <a href="https://arxiv.org/abs/2404.18423" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
                  <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a> -->
                  <a href="https://github.com/yeonjisong/object-centric-kinematics" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>

                </div>
                <!-- Hidden abstract block -->
                <div class="abstract hidden">
                  <p>
                    Human perception involves discerning complex multi-object scenes into time-static object appearance (\ie, size, shape, color) and time-varying object motion (\ie, location, velocity, acceleration). This innate ability to unconsciously understand the environment is the motivation behind the success of dynamics modeling. Object-centric representations have emerged as a promising tool for dynamics prediction, yet they primarily focus on the objects' appearance, often overlooking other crucial attributes. In this paper, we propose Object-Centric Kinematics (OCK), a framework for dynamics prediction leveraging object-centric representations. Our model utilizes a novel component named object kinematics, which comprises low-level structured states of objects' position, velocity, and acceleration. The object kinematics are obtained via either implicit or explicit approaches, enabling comprehensive spatiotemporal object reasoning, and integrated through various transformer mechanisms, facilitating effective object-centric dynamics modeling. Our model demonstrates superior performance when handling objects and backgrounds in complex scenes characterized by a wide range of object attributes and dynamic movements. Moreover, our model demonstrates generalization capabilities across diverse synthetic environments, highlighting its potential for broad applicability in vision-related tasks.
                  </p>
                </div>
              </div>
            </div>
          </li>
          <li>
            <div class="row">
              <div class="col-sm-2 abbr">
                <abbr class="badge">arXiv</abbr>
                <!-- <span class="award badge">Oral</span> -->
              </div>
              <div id="" class="col-sm-8">
                <div class="title">Continuous SO(3) Equivariant Convolution for 3D Point Cloud Analysis</div>
                <div class="author">
                  Jaein Kim, Heebin Yoo, Dong-Sig Han, <em>Yeon-Ji Song</em>, Byoung-Tak Zhang
                </div>
                <div class="periodical">
                  <em>Under review</em>
                  <!-- ,2024 -->
                </div>   

                <div class="links">
                  <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                  <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
                  <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a> -->
                  <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a> -->

                </div>
                <!-- Hidden abstract block -->
                <div class="abstract hidden">
                  <p>abs
                  </p>
                </div>
              </div>
            </div>
          </li>
          <li>
            <div class="row">
              <div class="col-sm-2 abbr">
                <abbr class="badge">arXiv</abbr>
                <!-- <span class="award badge">Oral</span> -->
              </div>
              <div id="" class="col-sm-8">
                <div class="title">Unsupervised Visual Dynamics Learning with Object Kinematics</div>
                <div class="author">
                  <em>Yeon-Ji Song</em>, Byoung-Tak Zhang
                </div>
                <div class="periodical">
                  <em>Under review</em>
                  <!-- ,2022 -->
                </div>   

                <div class="links">
                  <!-- <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> -->
                  <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> -->
                  <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a> -->
                  <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a> -->

                </div>
                <!-- Hidden abstract block -->
                <div class="abstract hidden">
                  <p>abs</p>
                </div>
              </div>
            </div>
          </li>
        </ol>


        <h2 class="year">2023</h2>
        <ol class="bibliography">

          <li>
            <div class="row">
              <div class="col-sm-2 abbr">
                <abbr class="badge">NeurIPS</abbr>
                <!-- <span class="award badge">Oral</span> -->
              </div>
              <div id="" class="col-sm-8">
                <div class="title">Learning Object Appearance and Motion Dynamics with Object-Centric Representations</div>
                <div class="author">
                  <em>Yeon-Ji Song</em>, Hyunseo Kim, Suhyung Choi, Jin-Hwa Kim*, Byoung-Tak Zhang*
                </div>
                <div class="periodical">
                  <em>NeurIPS Workshop on Causal Representation Learning</em>,
                  2023
                </div>   

                <div class="links">
                  <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                  <a href="https://openreview.net/forum?id=yzKb3uFiir" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
                  <a href="https://crl-workshop.github.io/" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a>
                  <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a> -->

                </div>
                <!-- Hidden abstract block -->
                <div class="abstract hidden">
                  <p>Human perception involves discerning objects based on attributes such as size, color, and texture, and making predictions about their movements using features such as weight and speed. This innate ability operates without the need for conscious learning, allowing individuals to perform actions like catching or avoiding objects when they are unaware. Accordingly, the fundamental key to achieving higher-level cognition lies in the capability to break down intricate multi-object scenes into meaningful appearances. Object-centric representations have emerged as a promising tool for scene decomposition by providing useful abstractions. In this paper, we propose a novel approach to unsupervised video prediction leveraging object-centric representations. Our methodology introduces a two-component model consisting of a slot encoder for object-centric disentanglement and a feature extraction module for masked patches. These components are integrated through a cross-attention mechanism, allowing for comprehensive spatio-temporal reasoning. Our model exhibits better performance when dealing with intricate scenes characterized by a wide range of object attributes and dynamic movements. Moreover, our approach demonstrates scalability across diverse synthetic environments, thereby showcasing its potential for widespread utilization in vision-related tasks.</p>
                </div>
              </div>
            </div>
          </li>

          <li>
            <div class="row">
              <div class="col-sm-2 abbr">
                <abbr class="badge">CLeaR</abbr>
                <!-- <span class="award badge">Oral</span> -->
              </div>
              <div id="" class="col-sm-8">
                <div class="title">On Discovery of Local Independence over Continuous Variables via Neural Contextual Decomposition</div>
                <div class="author">
                  Inwoo Hwang, Yunhyeok Kwak, <em>Yeon-Ji Song</em>, Byoung-Tak Zhang*, Sanghack Lee*
                </div>
                <div class="periodical">
                  <em>The 2nd Conference on Causal Learning and Reasoning (CLeaR)</em>,
                  2023
                </div>   

                <div class="links">
                  <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                  <a href="https://openreview.net/forum?id=-aFd28Uy9td" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
                  <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a> -->
                  <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a> -->

                </div>
                <!-- Hidden abstract block -->
                <div class="abstract hidden">
                  <p>Conditional independence provides a way to understand causal relationships among the variables of interest. An underlying system may exhibit more fine-grained causal relationships especially between a variable and its parents, which will be called the local independence relationships. One of the most widely studied local relationships is Context-Specific Independence (CSI), which holds in a specific assignment of conditioned variables. However, its applicability is often limited since it does not allow continuous variables: data conditioned to the specific value of a continuous variable contains few instances, if not none, making it infeasible to test independence. In this work, we define and characterize the local independence relationship that holds in a specific set of joint assignments of parental variables, which we call context-set specific independence (CSSI). We then provide a canonical representation of CSSI and prove its fundamental properties. Based on our theoretical findings, we cast the problem of discovering multiple CSSI relationships in a system as finding a partition of the joint outcome space. Finally, we propose a novel method, coined neural contextual decomposition (NCD), which learns such partition by imposing each set to induce CSSI via modeling a conditional distribution. We empirically demonstrate that the proposed method successfully discovers the ground truth local independence relationships in both synthetic dataset and complex system reflecting the real-world physical dynamics.</p>
                </div>
              </div>
            </div>
          </li>

          <li>
            <div class="row">
              <div class="col-sm-2 abbr">
                <abbr class="badge">KSC</abbr>
                <!-- <span class="award badge">Oral</span> -->
              </div>
              <div id="" class="col-sm-8">
                <div class="title">Unsupervised Video Prediction with Object-Centric Representations</div>
                <div class="author">
                  <em>Yeon-Ji Song</em>, Byoung-Tak Zhang
                </div>
                <div class="periodical">
                  <em>Proc. Korea Software Congress</em>,
                  2023
                </div>   

                <div class="links">
                  <!-- <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> -->
                  <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> -->
                  <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a> -->
                  <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a> -->

                </div>
                <!-- Hidden abstract block -->
                <div class="abstract hidden">
                  <p>abs</p>
                </div>
              </div>
            </div>
          </li>

        </ol>

        <h2 class="year">2022</h2>
        <ol class="bibliography">

         <li>
          <div class="row">
            <div class="col-sm-2 abbr">
              <abbr class="badge">KSC</abbr>
              <!-- <span class="award badge">Oral</span> -->
            </div>
            <div id="" class="col-sm-8">
              <div class="title">Self-Supervised Reinforcement Learning with Object-Centric Representations</div>
              <div class="author">
                <em>Yeon-Ji Song</em>, Inwoo Hwang, Byoung-Tak Zhang
              </div>
              <div class="periodical">
                <em>Proc. Korea Software Congress</em>,
                2022
              </div>   

              <div class="links">
                <!-- <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> -->
                <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> -->
                <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a> -->
                <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a> -->

              </div>
              <!-- Hidden abstract block -->
              <div class="abstract hidden">
                <p>abs</p>
              </div>
            </div>
          </div>
        </li>

        <li>
          <div class="row">
            <div class="col-sm-2 abbr">
              <abbr class="badge">KCC</abbr>
              <!-- <span class="award badge">Oral</span> -->
            </div>
            <div id="" class="col-sm-8">
              <div class="title">Self-Supervised Multi-Object Reinforcement Learning via Mutual Information</div>
              <div class="author">
                <em>Yeon-Ji Song</em>, Chang-Hoon Jeong, Byoung-Tak Zhang
              </div>
              <div class="periodical">
                <em>Proc. Korea Computer Congress</em>,
                2022
              </div>   

              <div class="links">
                <!-- <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> -->
                <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> -->
                <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a> -->
                <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a> -->

              </div>
              <!-- Hidden abstract block -->
              <div class="abstract hidden">
                <p>abs</p>
              </div>
            </div>
          </div>
        </li>
      </ol>

      <h2 class="year">2021</h2>
      <ol class="bibliography">

        <li>
          <div class="row">
            <div class="col-sm-2 abbr">
              <abbr class="badge">KCC</abbr>
              <!-- <span class="award badge">Oral</span> -->
            </div>
            <div id="" class="col-sm-8">
              <div class="title">Deep RL-based Optimal Path Planning and Obstacle Avoidance for Mobile Robots</div>
              <div class="author">
                <em>Yeon-Ji Song</em>, Youngjae Yoo, Chung-Yeon Lee, Byoung-Tak Zhang
              </div>
              <div class="periodical">
                <em>Proc. Korea Computer Congress</em>,
                2021
              </div>   

              <div class="links">
                <!-- <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> -->
                <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> -->
                <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a> -->
                <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a> -->

              </div>
              <!-- Hidden abstract block -->
              <div class="abstract hidden">
                <p>abs</p>
              </div>
            </div>
          </div>
        </li>

      </ol>

    </div>
  <br>
  <br>
  </article>


<!-- Footer -->



</body>

<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

<!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>


<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="./js/mansory.js" type="text/javascript"></script>





<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-180825462-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'UA-180825462-1');
</script>


<!-- Load Common JS -->
<script src="./js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="./js/dark_mode.js"></script>


</html>
