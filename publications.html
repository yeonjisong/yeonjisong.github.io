
<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Publications</title>
  <meta name="description" content="Yeon-Ji's personal website">

  <!-- Open Graph -->


  <!-- Bootstrap & MDB -->
  <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

  <!-- Fonts & Icons -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
  <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

  <!-- Code Syntax Highlighting -->
  <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

  <!-- Styles -->
  <link rel="shortcut icon" href="/assets/img/favicon.ico">
  <link rel="stylesheet" href="main.css">

  <link rel="canonical" href="publication">

  <!-- Theming-->



  <!-- MathJax -->
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


</head>

<body class="fixed-top-nav sticky-bottom-footer">

  <!-- Header -->

  <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
      <div class="container">

        <a class="navbar-brand title font-weight-lighter" href="./index.html">
         <span class="font-weight-bold">Yeon-Ji Song</span>
       </a>

       <!-- Navbar Toogle -->
       <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <li class="nav-item ">
            <a class="nav-link" href="index.html">About</a>
          </li>        
          <li class="nav-item active">
            <a class="nav-link" href="publications.html">
              Publications
              <span class="sr-only">(current)</span>
            </a>
          </li>

          <li class="nav-item ">
            <a class="nav-link" target="_blank" href="cv.pdf">CV</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

</header>


<!-- Content -->

<div class="container mt-5">
  <div class="post">

    <header class="post-header">
      <h1 class="post-title">Publications</h1>
      <p class="post-description">
        (&#x2A) denotes corresponding authors. <br>
        (&#x23) denotes equal contribution.
      </p>
    </header>

    <article>
      An up-to-date list is available on <a href="https://scholar.google.com/citations?user=CK_unFIAAAAJ&hl=en" target="\_blank">Google Scholar</a>
      <div class="publications">
<!-- 
        <h2 class="year">2025</h2>  
        <ol class="bibliography">
          <li>
            <div class="row">
              <div class="col-sm-2 abbr">
                <abbr class="badge">arXiv</abbr>
              </div>
              <div id="" class="col-sm-8">
                <div class="title">SOMAtic: 3D Gaussian Splatting for Robot Manipulation</div>
                <div class="author">
                  <em>Yeon-Ji Song</em>, Byoung-Tak Zhang*
                </div>
                <div class="periodical">
                  <em>Under review</em>
                </div>   
                <div class="links">
                  <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                  <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
                  <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
                </div>
                <div class="abstract hidden">
                  <p>
                    abs
                  </p>
                </div>
              </div>
            </div>
          </li>
        </ol>
 -->

        <h2 class="year">2024</h2>
        <ol class="bibliography">
<!--         <li>
            <div class="row">
              <div class="col-sm-2 abbr">
                <abbr class="badge">arXiv</abbr>
              </div>
              <div id="" class="col-sm-8">
                <div class="title">BOMA-GS: Learning Blurred Object Motion and Appearance via Sparse-Controlled Gaussian Splatting</div>
                <div class="author">
                  <em>Yeon-Ji Song</em>, Jaein Kim, Byoung-Tak Zhang*
                </div>
                <div class="periodical">
                  <em>In Progress</em>
                </div>   

                <div class="links">
                </div>
                <div class="abstract hidden">
                  <p>
                    abs
                  </p>
                </div>
              </div>
            </div>
          </li> -->
          <li>
            <div class="row">
              <div class="col-sm-2 abbr">
                <abbr class="badge">arXiv</abbr>
                <!-- <span class="award badge">Workshop</span> -->
              </div>
              <div id="" class="col-sm-8">
                <div class="title">Motion-aware Dynamic View Synthesis from Blurry Monocular Video via Sparse-Controlled Gaussian Splatting</div>
                <div class="author">
                  <!-- <em>Yeon-Ji Song</em>, Byoung-Tak Zhang* -->
                </div>
                <div class="periodical">
                  <em>Under review</em>
                </div>   

                <div class="links">
                  <!-- <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> -->
                  <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> -->
                  <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a> -->
                </div>
                <div class="abstract hidden">
                  <p>
                    abs
                  </p>
                </div>
              </div>
            </div>
          </li>
          <!-- <li>
            <div class="row">
              <div class="col-sm-2 abbr">
                <abbr class="badge">arXiv</abbr>
                <span class="award badge">Workshop</span>
              </div>
              <div id="" class="col-sm-8">
                <div class="title">Motion-aware Gaussian Splatting from Blurred Monocular Video </div>
                <div class="author">
                  <em>Yeon-Ji Song</em>, Byoung-Tak Zhang*
                </div>
                <div class="periodical">
                  <em>Under Review</em>
                </div>   

                <div class="links">
                </div>
                <div class="abstract hidden">
                  <p>
                    abs
                  </p>
                </div>
              </div>
            </div>
          </li> -->
          <li>
            <div class="row">
              <div class="col-sm-2 abbr">
                <abbr class="badge">arXiv</abbr>
                <!-- <span class="award badge">Oral</span> -->
              </div>
              <div id="" class="col-sm-8">
                <div class="title">Unsupervised Dynamic Video Prediction with Object-Centric Kinematics</div>
                <div class="author">
                  <em>Yeon-Ji Song</em>, Suhyung Choi, Jaein Kim, Jin-Hwa Kim*, Byoung-Tak Zhang*
                </div>
                <div class="periodical">
                  <em>Under review</em>
                  <!-- ,2024 -->
                </div>   

                <div class="links">
                  <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                  <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
                  <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a> -->
                  <a href="https://github.com/yeonjisong/object-centric-kinematics" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>

                </div>
                <!-- Hidden abstract block -->
                <div class="abstract hidden">
                  <p>
                    Human perception involves discerning complex multi-object scenes into time-static object appearance (i.e., size, shape, color) and time-varying object motion (i.e., position, velocity, acceleration). For machines to interact in the real world in a manner akin to human intelligence, they must comprehend the physical properties of objects, which is the motivation for successful video prediction. Recently, transformers with object-centric representations have emerged as promising for video prediction, yet they primarily focus on objectsâ€™ appear- ance, often overlooking other crucial attributes. In this paper, we propose Object-Centric Kinematics (OCK), a framework for dynamic video prediction leveraging object-centric rep- resentations. We introduce a novel component named Object Kinematics, which comprises low-level structured states of objects, thereby capturing objectsâ€™ motion as an additional attribute on top of objectsâ€™ appearance. The Object Kinemat- ics are obtained via diverse approaches, enabling compre- hensive spatiotemporal object reasoning, and are integrated through various transformer mechanisms, facilitating effec- tive dynamic long-term video prediction and generation. Our model demonstrates superior performance in handling objects and backgrounds within complex scenes characterized by di- verse object attributes and motions. Furthermore, our model exhibits long-term generalization capabilities, highlighting its potential for broad applicability in vision-related tasks.
                  </p>
                </div>
              </div>
            </div>
          </li>
          <li>
            <div class="row">
              <div class="col-sm-2 abbr">
                <abbr class="badge">ECCV</abbr>
                <!-- <span class="award badge">Oral</span> -->
              </div>
              <div id="" class="col-sm-8">
                <div class="title">Continuous SO(3) Equivariant Convolution for 3D Point Cloud Analysis</div>
                <div class="author">
                  Jaein Kim, Heebin Yoo, Dong-Sig Han, <em>Yeon-Ji Song</em>, Byoung-Tak Zhang*
                </div>
                <div class="periodical">
                  <em>The 18th European Conference on Computer Vision (ECCV), 2024</em>
                  <!-- ,2024 -->
                </div>   

                <div class="links">
                  <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                  <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
                  <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a> -->
                  <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a> -->

                </div>
                <!-- Hidden abstract block -->
                <div class="abstract hidden">
                  <p>
                    The inherent richness of geometric information in point cloud underscores the necessity of leveraging group equivariance, as preserving the topological structure of the point cloud up to the feature space provides an intuitive inductive bias for solving problems in 3D space. Since manifesting the symmetry by means of model architecture has an advantage over the dependence on the augmentation, it has been a crucial research topic in the point cloud field. However, existing methods have limitations in the non-continuity of groups or the complex architecture causing computational inefficiency. In this paper, we propose CSEConv: a novel point convolution layer equivariant under continuous SO(3) actions. Its structure is founded on the framework of group theory, realizing the convolution module defined on a sphere. Implementing its filters to be explicit, continuous, and rigorously equivariant functions defined upon the double coset space is the distinctive factor which makes our method more scalable than previous approaches. From the classification experiments on synthetic and real-world point cloud datasets, our method achieves the best accuracy, to the best of our knowledge, amidst point-based models equivariant against continuous rotation group.
                  </p>
                </div>
              </div>
            </div>
          </li>
        </ol>


        <h2 class="year">2023</h2>
        <ol class="bibliography">

          <li>
            <div class="row">
              <div class="col-sm-2 abbr">
                <abbr class="badge">NeurIPS</abbr>
                <span class="award badge">Workshop</span>
              </div>
              <div id="" class="col-sm-8">
                <div class="title">Learning Object Appearance and Motion Dynamics with Object-Centric Representations</div>
                <div class="author">
                  <em>Yeon-Ji Song</em>, Hyunseo Kim, Suhyung Choi, Jin-Hwa Kim*, Byoung-Tak Zhang*
                </div>
                <div class="periodical">
                  <em>NeurIPS Workshop on Causal Representation Learning</em>,
                  2023
                </div>   

                <div class="links">
                  <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                  <a href="https://openreview.net/forum?id=yzKb3uFiir" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
                  <a href="https://crl-workshop.github.io/" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a>
                  <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a> -->

                </div>
                <!-- Hidden abstract block -->
                <div class="abstract hidden">
                  <p>Human perception involves discerning objects based on attributes such as size, color, and texture, and making predictions about their movements using features such as weight and speed. This innate ability operates without the need for conscious learning, allowing individuals to perform actions like catching or avoiding objects when they are unaware. Accordingly, the fundamental key to achieving higher-level cognition lies in the capability to break down intricate multi-object scenes into meaningful appearances. Object-centric representations have emerged as a promising tool for scene decomposition by providing useful abstractions. In this paper, we propose a novel approach to unsupervised video prediction leveraging object-centric representations. Our methodology introduces a two-component model consisting of a slot encoder for object-centric disentanglement and a feature extraction module for masked patches. These components are integrated through a cross-attention mechanism, allowing for comprehensive spatio-temporal reasoning. Our model exhibits better performance when dealing with intricate scenes characterized by a wide range of object attributes and dynamic movements. Moreover, our approach demonstrates scalability across diverse synthetic environments, thereby showcasing its potential for widespread utilization in vision-related tasks.</p>
                </div>
              </div>
            </div>
          </li>

          <li>
            <div class="row">
              <div class="col-sm-2 abbr">
                <abbr class="badge">CLeaR</abbr>
                <!-- <span class="award badge">Oral</span> -->
              </div>
              <div id="" class="col-sm-8">
                <div class="title">On Discovery of Local Independence over Continuous Variables via Neural Contextual Decomposition</div>
                <div class="author">
                  Inwoo Hwang, Yunhyeok Kwak, <em>Yeon-Ji Song</em>, Byoung-Tak Zhang*, Sanghack Lee*
                </div>
                <div class="periodical">
                  <em>The 2nd Conference on Causal Learning and Reasoning (CLeaR)</em>,
                  2023
                </div>   

                <div class="links">
                  <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
                  <a href="https://openreview.net/forum?id=-aFd28Uy9td" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
                  <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a> -->
                  <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a> -->

                </div>
                <!-- Hidden abstract block -->
                <div class="abstract hidden">
                  <p>Conditional independence provides a way to understand causal relationships among the variables of interest. An underlying system may exhibit more fine-grained causal relationships especially between a variable and its parents, which will be called the local independence relationships. One of the most widely studied local relationships is Context-Specific Independence (CSI), which holds in a specific assignment of conditioned variables. However, its applicability is often limited since it does not allow continuous variables: data conditioned to the specific value of a continuous variable contains few instances, if not none, making it infeasible to test independence. In this work, we define and characterize the local independence relationship that holds in a specific set of joint assignments of parental variables, which we call context-set specific independence (CSSI). We then provide a canonical representation of CSSI and prove its fundamental properties. Based on our theoretical findings, we cast the problem of discovering multiple CSSI relationships in a system as finding a partition of the joint outcome space. Finally, we propose a novel method, coined neural contextual decomposition (NCD), which learns such partition by imposing each set to induce CSSI via modeling a conditional distribution. We empirically demonstrate that the proposed method successfully discovers the ground truth local independence relationships in both synthetic dataset and complex system reflecting the real-world physical dynamics.</p>
                </div>
              </div>
            </div>
          </li>

        </ol>

    <h2 class="year">others</h2>
      <ol class="bibliography">
          <li>
            <div class="row">
              <div class="col-sm-2 abbr">
                <!-- <abbr class="badge">&nbsp</abbr> -->
              </div>
              <div id="" class="col-sm-8">
                <div class="title">Sparse-Controlled Gaussian Splatting from Blurry Images</div>
                <div class="author">
                  <!-- <em>Yeon-Ji Song</em>, Jaein Kim, Byoung-Tak Zhang* -->
                </div>
                <div class="periodical">
                  <em>Under review</em>
                  <!-- <em>Proc. Korea Software Congress, 2024</em> -->
                </div>
                <!-- <div>
                  <h7>âœ¨ Best Presentation Award</h7>
                </div> -->
                <div class="links">
                </div>
                <!-- Hidden abstract block -->
                <div class="abstract hidden">
                  <p>abs</p>
                </div>
              </div>
            </div>
          </li>
          <li>
            <div class="row">
              <div class="col-sm-2 abbr">
                <abbr class="badge">KCC</abbr>
              </div>
              <div id="" class="col-sm-8">
                <div class="title">Unsupervised Visual Dynamics Learning with Multi-Object Kinematics</div>
                <div class="author">
                  <em>Yeon-Ji Song</em>, Byoung-Tak Zhang*
                </div>
                <div class="periodical">
                  <em>Proc. Korea Computer Congress, 2024</em>
                </div>
                <div>
                  <h7>âœ¨ Best Presentation Award</h7>
                </div>
                <div class="links">
                  <!-- <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> -->
                  <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> -->
                  <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a> -->
                  <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a> -->

                </div>
                <!-- Hidden abstract block -->
                <div class="abstract hidden">
                  <p>abs</p>
                </div>
              </div>
            </div>
          </li>
          <li>
            <div class="row">
              <div class="col-sm-2 abbr">
                <abbr class="badge">KSC</abbr>
                <span class="award badge">Oral</span>
              </div>
              <div id="" class="col-sm-8">
                <div class="title">Unsupervised Video Prediction with Object-Centric Representations</div>
                <div class="author">
                  <em>Yeon-Ji Song</em>, Byoung-Tak Zhang*
                </div>
                <div class="periodical">
                  <em>Proc. Korea Software Congress</em>,
                  2023
                </div>   
                <!-- Hidden abstract block -->
                <div class="abstract hidden">
                  <p>abs</p>
                </div>
              </div>
            </div>
          </li>
         <li>
          <div class="row">
            <div class="col-sm-2 abbr">
              <abbr class="badge">KSC</abbr>
                <span class="award badge">Oral</span>
            </div>
            <div id="" class="col-sm-8">
              <div class="title">Self-Supervised Reinforcement Learning with Object-Centric Representations</div>
              <div class="author">
                <em>Yeon-Ji Song</em>, Inwoo Hwang, Byoung-Tak Zhang*
              </div>
              <div class="periodical">
                <em>Proc. Korea Software Congress</em>,
                2022
              </div>   
              <!-- Hidden abstract block -->
              <div class="abstract hidden">
                <p>abs</p>
              </div>
            </div>
          </div>
        </li>

        <li>
          <div class="row">
            <div class="col-sm-2 abbr">
              <abbr class="badge">KCC</abbr>
              <!-- <span class="award badge">Oral</span> -->
            </div>
            <div id="" class="col-sm-8">
              <div class="title">Self-Supervised Multi-Object Reinforcement Learning via Mutual Information</div>
              <div class="author">
                <em>Yeon-Ji Song</em>, Chang-Hoon Jeong, Byoung-Tak Zhang*
              </div>
              <div class="periodical">
                <em>Proc. Korea Computer Congress</em>,
                2022
              </div>   

              <div class="links">
                <!-- <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> -->
                <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> -->
                <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a> -->
                <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a> -->

              </div>
              <!-- Hidden abstract block -->
              <div class="abstract hidden">
                <p>abs</p>
              </div>
            </div>
          </div>
        </li>
        <li>
          <div class="row">
            <div class="col-sm-2 abbr">
              <abbr class="badge">KCC</abbr>
              <!-- <span class="award badge">Oral</span> -->
            </div>
            <div id="" class="col-sm-8">
              <div class="title">Deep RL-based Optimal Path Planning and Obstacle Avoidance for Mobile Robots</div>
              <div class="author">
                <em>Yeon-Ji Song</em>, Youngjae Yoo, Chung-Yeon Lee, Byoung-Tak Zhang*
              </div>
              <div class="periodical">
                <em>Proc. Korea Computer Congress</em>,
                2021
              </div>   

              <div class="links">
                <!-- <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> -->
                <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> -->
                <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Website</a> -->
                <!-- <a href="" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a> -->

              </div>
              <!-- Hidden abstract block -->
              <div class="abstract hidden">
                <p>abs</p>
              </div>
            </div>
          </div>
        </li>


      </ol>
      
    </div>
  <br>
  <br>
  </article>


<!-- Footer -->



</body>

<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

<!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>


<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="./js/mansory.js" type="text/javascript"></script>





<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-180825462-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'UA-180825462-1');
</script>


<!-- Load Common JS -->
<script src="./js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="./js/dark_mode.js"></script>


</html>
